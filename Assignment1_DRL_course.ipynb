{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eya-methnani/Assignment-1---Deep-Reinforcement-Learning-Course/blob/main/Assignment1_DRL_course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ia8lTalyK2IV"
      },
      "outputs": [],
      "source": [
        "\"\"\"A simple world model\n",
        "\n",
        "Simple deterministic MDP is made of 6 grids (states)\n",
        "---------------------------------\n",
        "|         |          |          |\n",
        "|  Start  |          |  Goal    |\n",
        "|         |          |          |\n",
        "---------------------------------\n",
        "|         |          |          |\n",
        "|         |          |  Hole    |\n",
        "|         |          |          |\n",
        "---------------------------------\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import time\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "class QWorld:\n",
        "    def __init__(self):\n",
        "        \"\"\"Simulated deterministic world made of 6 states.\n",
        "        \"\"\"\n",
        "        # 4 actions\n",
        "        # 0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "        self.col = 4\n",
        "\n",
        "        # 6 states\n",
        "        self.row = 6\n",
        "\n",
        "        # setup the environment\n",
        "        self.init_transition_table()\n",
        "        self.init_reward_table()\n",
        "\n",
        "        # reset the environment\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"start of episode\"\"\"\n",
        "        self.state = 0\n",
        "        self.count = 0\n",
        "        return self.state\n",
        "\n",
        "    def is_in_win_state(self):\n",
        "        \"\"\"agent wins when the goal is reached\"\"\"\n",
        "        return self.state == 2\n",
        "\n",
        "\n",
        "    def init_reward_table(self):\n",
        "        \"\"\"\n",
        "        0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "        ----------------\n",
        "        | 0 | 0 | 100  |\n",
        "        ----------------\n",
        "        | 0 | 0 | -100 |\n",
        "        ----------------\n",
        "        \"\"\"\n",
        "        #############################################\n",
        "        #TODO-- fill in the reward table\n",
        "        #############################################\n",
        "        self.reward_table = np.zeros([self.row, self.col])\n",
        "        # To be completed\n",
        "\n",
        "        self.reward_table[0, 2] = 100  # Moving right at state 0 to Goal\n",
        "        self.reward_table[1, 2] = 100  # Moving right at state 1 to Goal\n",
        "        self.reward_table[3, 2] = -100 # Moving right at state 3 to Hole\n",
        "        self.reward_table[4, 2] = -100 # Moving right at state 4 to Hole\n",
        "\n",
        "\n",
        "\n",
        "    def init_transition_table(self):\n",
        "        \"\"\"\n",
        "        actions:\n",
        "        0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "\n",
        "        states:\n",
        "        -------------\n",
        "        | 0 | 1 | 2 |\n",
        "        -------------\n",
        "        | 3 | 4 | 5 |\n",
        "        -------------\n",
        "        \"\"\"\n",
        "        self.transition_table = np.zeros([self.row, self.col],\n",
        "                                         dtype=int)\n",
        "\n",
        "        self.transition_table[0, 0] = 0\n",
        "        self.transition_table[0, 1] = 3\n",
        "        self.transition_table[0, 2] = 1\n",
        "        self.transition_table[0, 3] = 0\n",
        "\n",
        "        #############################################\n",
        "        #TODO-- complete the transition_table\n",
        "        #############################################\n",
        "        # to be completed\n",
        "\n",
        "         # State 1 transitions\n",
        "        self.transition_table[1, 0] = 0  # Left to state 0\n",
        "        self.transition_table[1, 1] = 4  # Down to state 4\n",
        "        self.transition_table[1, 2] = 2  # Right to state 2 (Goal)\n",
        "        self.transition_table[1, 3] = 1  # Up stays at 1\n",
        "\n",
        "        # State 2 (Goal) transitions\n",
        "        self.transition_table[2, :] = 2  # Any action stays at Goal\n",
        "\n",
        "        # State 3 transitions\n",
        "        self.transition_table[3, 0] = 3  # Left stays at 3\n",
        "        self.transition_table[3, 1] = 3  # Down stays at 3\n",
        "        self.transition_table[3, 2] = 4  # Right to state 4\n",
        "        self.transition_table[3, 3] = 0  # Up to state 0\n",
        "\n",
        "        # State 4 transitions\n",
        "        self.transition_table[4, 0] = 3  # Left to state 3\n",
        "        self.transition_table[4, 1] = 4  # Down stays at 4\n",
        "        self.transition_table[4, 2] = 5  # Right to state 5 (Hole)\n",
        "        self.transition_table[4, 3] = 1  # Up to state 1\n",
        "\n",
        "        # State 5 (Hole) transitions\n",
        "        self.transition_table[5, :] = 5  # Any action stays at Hole\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"execute the action on the environment\n",
        "        Argument:\n",
        "            action (tensor): An action in Action space\n",
        "        Returns:\n",
        "            next_state (tensor): next env state\n",
        "            reward (float): reward received by the agent\n",
        "            done (Bool): whether the terminal state\n",
        "                is reached\n",
        "        \"\"\"\n",
        "        # determine the next_state given state and action\n",
        "        next_state = self.transition_table[self.state, action]\n",
        "        # done is True if next_state is Goal or Hole\n",
        "        #############################################\n",
        "        #TODO\n",
        "        #############################################\n",
        "\n",
        "\n",
        "\n",
        "         # Check if the agent reached Goal (state 2) or Hole (state 5)\n",
        "        done = next_state in [2, 5]\n",
        "\n",
        "\n",
        "\n",
        "        # reward given the state and action\n",
        "        reward = self.reward_table[self.state, action]\n",
        "        # the enviroment is now in new state\n",
        "        self.state = next_state\n",
        "        self.count+=1\n",
        "        return next_state, reward, done\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def print_cell(self, row=0):\n",
        "        \"\"\"UI to display agent moving on the grid\"\"\"\n",
        "        print(\"\")\n",
        "        for i in range(13):\n",
        "            j = i - 2\n",
        "            if j in [0, 4, 8]:\n",
        "                if j == 8:\n",
        "                    if self.state == 2 and row == 0:\n",
        "                        marker = \"\\033[4mG\\033[0m\"\n",
        "                    elif self.state == 5 and row == 1:\n",
        "                        marker = \"\\033[4mH\\033[0m\"\n",
        "                    else:\n",
        "                        marker = 'G' if row == 0 else 'H'\n",
        "                    color = self.state == 2 and row == 0\n",
        "                    color = color or (self.state == 5 and row == 1)\n",
        "                    color = 'red' if color else 'blue'\n",
        "                    print(colored(marker, color), end='')\n",
        "                elif self.state in [0, 1, 3, 4]:\n",
        "                    cell = [(0, 0, 0), (1, 0, 4), (3, 1, 0), (4, 1, 4)]\n",
        "                    marker = '_' if (self.state, row, j) in cell else ' '\n",
        "                    print(colored(marker, 'red'), end='')\n",
        "                else:\n",
        "                    print(' ', end='')\n",
        "            elif i % 4 == 0:\n",
        "                    print('|', end='')\n",
        "            else:\n",
        "                print(' ', end='')\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "    def print_world(self, action):\n",
        "        \"\"\"UI to display mode and action of agent\"\"\"\n",
        "        actions = { 0: \"(Left)\", 1: \"(Down)\", 2: \"(Right)\", 3: \"(Up)\" }\n",
        "        if self.count==0:\n",
        "          print(\"Start Game\")\n",
        "        else:\n",
        "          print(\"Action : \", actions[action])\n",
        "        for _ in range(13):\n",
        "            print('-', end='')\n",
        "        self.print_cell()\n",
        "        for _ in range(13):\n",
        "            print('-', end='')\n",
        "        self.print_cell(row=1)\n",
        "        for _ in range(13):\n",
        "            print('-', end='')\n",
        "        print(\"\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_episode(episode, delay=1):\n",
        "    \"\"\"UI to display episode count\n",
        "    Arguments:\n",
        "        episode (int): episode number\n",
        "        delay (int): sec delay\n",
        "\n",
        "    \"\"\"\n",
        "    os.system('clear')\n",
        "    for _ in range(13):\n",
        "        print('=', end='')\n",
        "    print(\"\")\n",
        "    print(\"Episode \", episode)\n",
        "    for _ in range(13):\n",
        "        print('=', end='')\n",
        "    print(\"\")\n",
        "    time.sleep(delay)\n",
        "\n",
        "def print_status(q_world, done,action, delay=1):\n",
        "    \"\"\"UI to display the world,\n",
        "        delay of 1 sec for ease of understanding\n",
        "    \"\"\"\n",
        "    os.system('clear')\n",
        "    q_world.print_world(action)\n",
        "    if done:\n",
        "        print(\"-------EPISODE DONE--------\")\n",
        "        delay *= 2\n",
        "    time.sleep(delay)"
      ],
      "metadata": {
        "id": "xM3FVC9cYlwl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate the environment\n",
        "q_world = QWorld()\n"
      ],
      "metadata": {
        "id": "tCYOCOPBK7YR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TODO:**\n",
        "\n",
        "\n",
        "A) Complete the code in the cells above (the parts to be completed are marked with 'TODO')\n",
        "\n",
        "B) Once part A) is complete, implement now each of the following situations in **a separate cell**. For the sake of illustration, Situation 1 is already implemented for you to give you a hint on how to answer each part. You could implement somthing similar for Situation 2, Situation 3 and Situation 4.\n",
        "\n",
        "**Situation 1:**take agent to goal in 2 steps. Print the episode name and display the grid for each step taken.\n",
        "\n",
        "**Situation 2:** take agent to H in 3 steps. Print the episode name and display the grid for each step taken.\n",
        "\n",
        "**Situation 3:** implement the following trajectory: down-right-up-right. what's the cumulative reward (assume the discount factor is 1)? Compare with the cumulative reward of the episode from **Situation 1** and comment.\n",
        "Make sure the cumulative reward is printed when the cell is executed.\n",
        "\n",
        "**Situation 4:** Implement an agent that takes random actions at each step and stops only when the task is solved (note that your agent may need to go through multiple episodes before your it is able to reach the goal). After how many episodes it solved the task? (the number of episodes should be displayed automatically each time you run the cell)"
      ],
      "metadata": {
        "id": "CwvXZezFg2js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Situation 1\n",
        "# print initial grid --before taking any action--\n",
        "state = q_world.reset()\n",
        "done = False\n",
        "episode = 1\n",
        "delay = 0\n",
        "print_episode(episode=episode, delay=0)\n",
        "\n",
        "# print initial status of the board\n",
        "print_status(q_world, done, 0, delay=delay)\n",
        "\n",
        "\n",
        "# to take the agent to GOAL (G) in two steps, the agent needs\n",
        "# to go right then go right again\n",
        "\n",
        "# recall the actions:\n",
        "# 0 - Left, 1 - Down, 2 - Right, 3 - Up\n",
        "\n",
        "# 1- Go right\n",
        "action=2\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n",
        "\n",
        "# 1- Go right again\n",
        "action=2\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done,action, delay=delay)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUjj7jPFVSlU",
        "outputId": "2dae1a64-fb7a-4cfe-c9fc-9447fda93a54"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============\n",
            "Episode  1\n",
            "=============\n",
            "Start Game\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | \u001b[4mG\u001b[0m |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Situation 2\n",
        "# TODO\n",
        "\n",
        "# Situation 2: Take the agent to Hole (H) in 3 steps\n",
        "state = q_world.reset()\n",
        "done = False\n",
        "episode = 2\n",
        "delay = 0\n",
        "\n",
        "# Print Episode and Initial Grid\n",
        "print_episode(episode=episode, delay=0)\n",
        "print_status(q_world, done, 0, delay=delay)\n",
        "\n",
        "# 1- Go Down\n",
        "action = 1  # Down\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done, action, delay=delay)\n",
        "\n",
        "# 2- Go Right\n",
        "action = 2  # Right\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done, action, delay=delay)\n",
        "\n",
        "# 3- Go Right again\n",
        "action = 2  # Right\n",
        "next_state, reward, done = q_world.step(action)\n",
        "print_status(q_world, done, action, delay=delay)\n"
      ],
      "metadata": {
        "id": "4JY-_Hm9MD6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d1bc60-2e29-4d84-e728-e7cdb3f86c58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============\n",
            "Episode  2\n",
            "=============\n",
            "Start Game\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   |   | \u001b[4mH\u001b[0m |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Situation 3\n",
        "# TODO\n",
        "\n",
        "# Situation 3: Down → Right → Up → Right\n",
        "state = q_world.reset()\n",
        "done = False\n",
        "episode = 3\n",
        "delay = 0\n",
        "cumulative_reward = 0\n",
        "\n",
        "# Print Episode and Initial Grid\n",
        "print_episode(episode=episode, delay=0)\n",
        "print_status(q_world, done, 0, delay=delay)\n",
        "\n",
        "# 1- Go Down\n",
        "action = 1  # Down\n",
        "next_state, reward, done = q_world.step(action)\n",
        "cumulative_reward += reward\n",
        "print_status(q_world, done, action, delay=delay)\n",
        "\n",
        "# 2- Go Right\n",
        "action = 2  # Right\n",
        "next_state, reward, done = q_world.step(action)\n",
        "cumulative_reward += reward\n",
        "print_status(q_world, done, action, delay=delay)\n",
        "\n",
        "# 3- Go Up\n",
        "action = 3  # Up\n",
        "next_state, reward, done = q_world.step(action)\n",
        "cumulative_reward += reward\n",
        "print_status(q_world, done, action, delay=delay)\n",
        "\n",
        "# 4- Go Right\n",
        "action = 2  # Right\n",
        "next_state, reward, done = q_world.step(action)\n",
        "cumulative_reward += reward\n",
        "print_status(q_world, done, action, delay=delay)\n",
        "\n",
        "# Print the cumulative reward\n",
        "print(\"Cumulative Reward for Situation 3:\", cumulative_reward)\n",
        "\n",
        "# Compare with Situation 1 (Goal reward is +100)\n",
        "print(\"Cumulative Reward for Situation 1: 100\")\n",
        "if cumulative_reward < 100:\n",
        "    print(\"The trajectory in Situation 3 is suboptimal compared to Situation 1.\")\n",
        "else:\n",
        "    print(\"The trajectory in Situation 3 matches Situation 1.\")\n"
      ],
      "metadata": {
        "id": "D7pnyph8iITn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355226aa-f364-4a4c-df9d-89b3c584adb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============\n",
            "Episode  3\n",
            "=============\n",
            "Start Game\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | \u001b[4mG\u001b[0m |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "Cumulative Reward for Situation 3: 0.0\n",
            "Cumulative Reward for Situation 1: 100\n",
            "The trajectory in Situation 3 is suboptimal compared to Situation 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Situation 4\n",
        "# TODO\n",
        "\n",
        "import random\n",
        "\n",
        "# Situation 4: Random actions until the task is solved\n",
        "episode = 0\n",
        "delay = 0\n",
        "solved = False\n",
        "\n",
        "while not solved:\n",
        "    state = q_world.reset()\n",
        "    done = False\n",
        "    episode += 1\n",
        "\n",
        "    # Print the episode header\n",
        "    print_episode(episode=episode, delay=0)\n",
        "\n",
        "    # Run the episode\n",
        "    while not done:\n",
        "        action = random.choice([0, 1, 2, 3])  # Random action\n",
        "        next_state, reward, done = q_world.step(action)\n",
        "        print_status(q_world, done, action, delay=delay)\n",
        "\n",
        "        # Check if the task is solved\n",
        "        if done and next_state == 2:  # Goal state\n",
        "            solved = True\n",
        "            print(f\"Task solved in {episode} episodes!\")\n",
        "            break\n"
      ],
      "metadata": {
        "id": "jdApmbmYXWdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f005e6f1-b305-4523-deca-c89dcf2d7f8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============\n",
            "Episode  1\n",
            "=============\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   |   | \u001b[4mH\u001b[0m |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "=============\n",
            "Episode  2\n",
            "=============\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   |   | \u001b[4mH\u001b[0m |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "=============\n",
            "Episode  3\n",
            "=============\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   |   | \u001b[4mH\u001b[0m |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "=============\n",
            "Episode  4\n",
            "=============\n",
            "Action :  (Left)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Down)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "|   | _ | H |\n",
            "-------------\n",
            "Action :  (Left)\n",
            "-------------\n",
            "|   |   | G |\n",
            "-------------\n",
            "| _ |   | H |\n",
            "-------------\n",
            "Action :  (Up)\n",
            "-------------\n",
            "| _ |   | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   | _ | G |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "Action :  (Right)\n",
            "-------------\n",
            "|   |   | \u001b[4mG\u001b[0m |\n",
            "-------------\n",
            "|   |   | H |\n",
            "-------------\n",
            "-------EPISODE DONE--------\n",
            "Task solved in 4 episodes!\n"
          ]
        }
      ]
    }
  ]
}